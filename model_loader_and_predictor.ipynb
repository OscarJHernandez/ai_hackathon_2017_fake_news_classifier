{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Number:  18978\n",
      "Testing Set Number:  4745\n",
      "==============================================================\n",
      "The Size of the dictionary 119893\n",
      "Top Dictionary Words:  [('the', 1925), ('trump', 1016), ('to', 910), ('hillary', 691), ('in', 648), ('us', 634), ('new', 629), ('is', 616), ('clinton', 615), ('of', 513)]\n",
      "Dictionary Creation is Complete\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================================\n",
    "# This Program will load the pre-trained models along with the confusion matrix results \n",
    "#=============================================================================================\n",
    "\n",
    "import cPickle\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import numerical_routines as nr\n",
    "import collections \n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# Import a lot of models...\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "\n",
    "# Import Tree Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# Here we read in the data-set of real and fake news items\n",
    "real_and_fake_df = pd.read_csv('real-and-fake-news-titles/fake_and_real_news_titles.csv')\n",
    "real_and_fake_df.head()\n",
    "\n",
    "# Take a subset of the data\n",
    "# 23,723\n",
    "#real_and_fake_df = real_and_fake_df[0:100]\n",
    "\n",
    "# The size of the dictionary array vectors\n",
    "dictionary_size = 3000\n",
    "\n",
    "\n",
    "# Now we split the data into the training set and test data set\n",
    "split_frac = 0.8\n",
    "data_set_size = len(real_and_fake_df)\n",
    "split_indx = int(data_set_size*split_frac)\n",
    "\n",
    "training_df = real_and_fake_df[:split_indx]\n",
    "testing_df = real_and_fake_df[split_indx:]\n",
    "\n",
    "training_size = len(training_df)\n",
    "testing_size = len(testing_df)\n",
    "\n",
    "print 'Training Set Number: ', training_size\n",
    "print 'Testing Set Number: ', testing_size\n",
    "\n",
    "# Now the data from the story titles is extracted into one large array containing all words in the title\n",
    "title_words_array = nr.aggregate_data(training_df.dropna(subset=['title']),size= training_size)\n",
    "#print title_words_array\n",
    "# Now we make filter the title words \n",
    "filtered_title_words_array = nr.create_dictionary(title_words_array)\n",
    "\n",
    "\n",
    "# Now we count the frequency of the different words\n",
    "dictionary = collections.Counter(filtered_title_words_array)\n",
    "\n",
    "list_to_remove = dictionary.keys()\n",
    "\n",
    "# Remove one character items \n",
    "for key in list_to_remove:\n",
    "    \n",
    "    if len(key) == 1:\n",
    "        del dictionary[key]\n",
    "\n",
    "# Now take a reasonable subset of the data\n",
    "dictionary = dictionary.most_common(dictionary_size)\n",
    "\n",
    "print '=============================================================='\n",
    "print 'The Size of the dictionary', len(filtered_title_words_array)\n",
    "print 'Top Dictionary Words: ', dictionary[0:10] \n",
    "print 'Dictionary Creation is Complete'\n",
    "print '=============================================================='\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_size_3000_dataSet_23723_NB_MultiNomial.pkl\n",
      "dict_size_3000_dataSet_23723_SVC.pkl\n",
      "dict_size_3000_dataSet_23723_Tree_vote.pkl\n",
      "dict_size_3000_dataSet_23723_otherM_vote.pkl\n",
      "dict_size_3000_dataSet_23723_NB_vote.pkl\n",
      "==================================================================================================================\n",
      "Models loaded and Confusion Matrix Calculation Complete\n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================================\n",
    "#==================================================================================================================\n",
    "# We will load the graphs according to the parameters that you put at the beginning\n",
    "\n",
    "# The Name of the available models\n",
    "names = ['NB_MultiNomial.pkl','SVC.pkl','Tree_vote.pkl',\n",
    "         'DecTree.pkl','RandFor.pkl','Extree.pkl','otherM_vote.pkl',\n",
    "         'AdaB.pkl','gradB.pkl','KNneigh.pkl','tree_and_otherM_vote.pkl','NB_Gauss.pkl','NB_Bern.pkl','NB_vote.pkl']\n",
    "\n",
    "cm_names = ['NB_MultiNomial_cm.dat','SVC_cm.dat','Tree_vote_cm.dat',\n",
    "         'DecTree_cm.dat','RandFor_cm.dat','Extree_cm.dat','otherM_vote_cm.dat',\n",
    "         'AdaB_cm.dat','gradB_cm.dat','KNneigh_cm.dat','tree_and_otherM_vote_cm.dat','NB_Gauss_cm.dat','NB_Bern_cm.dat','NB_vote_cm.dat']\n",
    "\n",
    "    \n",
    "# Choose a specific Classifier\n",
    "names_indx = 0\n",
    "name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+names[names_indx]\n",
    "cm_name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+cm_names[names_indx]\n",
    "f = open(cm_name, 'r')\n",
    "cm0= pickle.load(f)\n",
    "print name\n",
    "with open(name, 'rb') as fid:\n",
    "    model0 = cPickle.load(fid)\n",
    "\n",
    "names_indx = 1\n",
    "name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+names[names_indx]\n",
    "cm_name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+cm_names[names_indx]\n",
    "f = open(cm_name, 'r')\n",
    "cm1= pickle.load(f)\n",
    "print name\n",
    "with open(name, 'rb') as fid:\n",
    "    model1 = cPickle.load(fid)\n",
    "\n",
    "names_indx = 2\n",
    "name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+names[names_indx]\n",
    "cm_name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+cm_names[names_indx]\n",
    "f = open(cm_name, 'r')\n",
    "cm2= pickle.load(f)\n",
    "print name\n",
    "with open(name, 'rb') as fid:\n",
    "    model2 = cPickle.load(fid) \n",
    "\n",
    "names_indx = 6\n",
    "name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+names[names_indx]\n",
    "cm_name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+cm_names[names_indx]\n",
    "f = open(cm_name, 'r')\n",
    "cm3= pickle.load(f)\n",
    "print name\n",
    "with open(name, 'rb') as fid:\n",
    "    model3 = cPickle.load(fid) \n",
    "\n",
    "names_indx = 13\n",
    "name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+names[names_indx]\n",
    "cm_name = 'dict_size_'+str(dictionary_size)+'_'+'dataSet_'+str(len(real_and_fake_df))+'_'+cm_names[names_indx]\n",
    "f = open(cm_name, 'r')\n",
    "cm4= pickle.load(f)\n",
    "print name\n",
    "with open(name, 'rb') as fid:\n",
    "    model4 = cPickle.load(fid) \n",
    "\n",
    "cm_array = [cm0,cm1,cm2,cm3,cm4]\n",
    "model_array = [model0,model1,model1,model3,model4]    \n",
    "\n",
    "print '=================================================================================================================='\n",
    "print 'Models loaded and Confusion Matrix Calculation Complete'\n",
    "print '=================================================================================================================='    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.]\n",
      "[ 1.]\n",
      "[ 0.]\n",
      "[ 1.]\n",
      "[ 0.]\n",
      "[0.53136788807461688, 0.46863211192538312]\n"
     ]
    }
   ],
   "source": [
    "text = 'Trudeau to appear at Sunday Pride parade in Toronto'\n",
    "text = 'Hilary'\n",
    "#text ='Panicking Mitch McConnell Shoves Entire Senate Healthcare Bill Into Mouth As Democrat Walks Past'\n",
    "print ''\n",
    "print nr.generate_predictions(text, dictionary, model0)\n",
    "print nr.generate_predictions(text, dictionary, model1)\n",
    "print nr.generate_predictions(text, dictionary, model2)\n",
    "print nr.generate_predictions(text, dictionary, model3)\n",
    "print nr.generate_predictions(text, dictionary, model4)\n",
    "print nr.Bayesian_Sequence_Prediction(text,dictionary,model_array,cm_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "News Headline:  EBay says Carl Icahns board picks not qualified\n",
      "\n",
      "Real News Confidence:  0.9072\n",
      "Fake News Confidence:  0.0928\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "news_headline = 'Panicking Mitch McConnell Shoves Entire Senate Healthcare Bill Into Mouth As Democrat Walks Past'\n",
    "news_headline = 'US open: Stocks fall after Fed official hints at accelerated tapering'\n",
    "news_headline = 'McDonalds Not Lovin US Sales'\n",
    "news_headline ='EBay says Carl Icahns board picks not qualified'\n",
    "\n",
    "print '============================================================\\n'\n",
    "print 'News Headline: ', news_headline\n",
    "print ''\n",
    "print 'Real News Confidence: ', nr.Bayesian_Sequence_Prediction(news_headline,dictionary,model_array,cm_array)[0]\n",
    "print 'Fake News Confidence: ', nr.Bayesian_Sequence_Prediction(news_headline,dictionary,model_array,cm_array)[1]\n",
    "print ''\n",
    "print '============================================================'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.3'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
